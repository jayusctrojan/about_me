{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayusctrojan/about_me/blob/master/Jay%20Bajaj%20-%20ik_agenteval_exercise1_llm_judge_homework_non_swe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Evaluation Homework for non-SWE\n",
        "\n",
        "This module demonstrates using LangSmith to monitor your agent in production. You need to have created a langsmith account, and have your custom openAI keys.\n"
      ],
      "metadata": {
        "id": "g8MaN8vLNULd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
        "\n",
        "Note that observability is important throughout all stages of application development - from prototyping, to beta testing, to production. There are different considerations at all stages, but they are all intricately tied together. In this tutorial we walk through the natural progression.\n",
        "\n",
        "Let's assume that we're building a simple RAG application using the OpenAI SDK. The simple application we're adding observability to looks like."
      ],
      "metadata": {
        "id": "CP6THF7ptowd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to homework document: https://docs.google.com/document/d/1IrgnVLXtHcx0TJ0IJlUzrHsqseM23eGh7DdpYEkzJvU/edit?tab=t.0\n"
      ],
      "metadata": {
        "id": "0C_SXreFIZlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install langsmith\n",
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "from langsmith import traceable\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
        "#os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "#os.environ[\"LANGSMITH_API_KEY\"] =  userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<enter-your-own-key-here>\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"<enter-your-own-key-here>\"\n",
        "\n",
        "# Verify they're set\n",
        "print(\"OpenAI key set:\", \"OPENAI_API_KEY\" in os.environ and len(os.environ[\"OPENAI_API_KEY\"]) > 0)\n",
        "print(\"LangSmith key set:\", \"LANGSMITH_API_KEY\" in os.environ and len(os.environ[\"LANGSMITH_API_KEY\"]) > 0)\n",
        "\n",
        "!pip install openai langsmith langchain-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8NREszw7el",
        "outputId": "56f7654e-f95f-40a7-9469-074114b125af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.27)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.3)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "OpenAI key set: True\n",
            "LangSmith key set: True\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.27)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.75)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.3)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.24.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1 - Running the first Basic App**\n",
        "\n",
        "Let's first build a basic LLM application, with a basic calls wrapped around LangSmith. Run the below, and check out what is showing up on the LangSmith Portal."
      ],
      "metadata": {
        "id": "vIAFEc5qGNU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = wrap_openai(OpenAI())\n",
        "\n",
        "def retriever(query: str):\n",
        "    results = [\"Harrison worked at Kensho\"]\n",
        "    return results\n",
        "\n",
        "def rag(question):\n",
        "    docs = retriever(question)\n",
        "    system_message = \"\"\"Answer the users question using only the provided information below:\n",
        "\n",
        "    {docs}\"\"\".format(docs=\"\\n\".join(docs))\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "3iaqyLrKGDhZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep LangSmith Debugging\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import requests\n",
        "import uuid\n",
        "\n",
        "print(\"üîç Deep LangSmith Debugging...\")\n",
        "\n",
        "# Load fresh from secrets\n",
        "langsmith_key = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = langsmith_key\n",
        "\n",
        "print(f\"‚úÖ Using Personal Access Token: {langsmith_key[:15]}...\")\n",
        "\n",
        "# Test 1: Check LangSmith API directly\n",
        "print(f\"\\nüß™ Test 1: Direct API Health Check\")\n",
        "try:\n",
        "    headers = {\"Authorization\": f\"Bearer {langsmith_key}\"}\n",
        "    response = requests.get(\"https://api.smith.langchain.com/info\", headers=headers)\n",
        "    print(f\"API Status: {response.status_code}\")\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ LangSmith API is accessible\")\n",
        "    else:\n",
        "        print(f\"‚ùå API issue: {response.status_code} - {response.text}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå API request failed: {e}\")\n",
        "\n",
        "# Test 2: Check Client initialization\n",
        "print(f\"\\nüß™ Test 2: Client Initialization\")\n",
        "try:\n",
        "    from langsmith import Client\n",
        "    ls_client = Client()\n",
        "    print(\"‚úÖ LangSmith Client created successfully\")\n",
        "\n",
        "    # Check if we can access basic info\n",
        "    try:\n",
        "        # This should work with any valid token\n",
        "        runs_iter = ls_client.list_runs(limit=1)\n",
        "        runs = list(runs_iter)\n",
        "        print(f\"‚úÖ Can list runs: {len(runs)} runs found\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Can't list runs: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Client creation failed: {e}\")\n",
        "\n",
        "# Test 3: Create a minimal trace and try feedback\n",
        "print(f\"\\nüß™ Test 3: Minimal Trace + Feedback Test\")\n",
        "try:\n",
        "    from langsmith import traceable\n",
        "\n",
        "    @traceable\n",
        "    def simple_test(input_text):\n",
        "        return f\"Processed: {input_text}\"\n",
        "\n",
        "    # Create a trace\n",
        "    test_run_id = str(uuid.uuid4())\n",
        "    print(f\"Creating trace with run_id: {test_run_id}\")\n",
        "\n",
        "    result = simple_test(\n",
        "        \"test input\",\n",
        "        langsmith_extra={\"run_id\": test_run_id}\n",
        "    )\n",
        "    print(f\"‚úÖ Trace created: {result}\")\n",
        "\n",
        "    # Wait a moment for the trace to be processed\n",
        "    import time\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Try to add feedback\n",
        "    print(f\"üß™ Attempting to add feedback to run_id: {test_run_id}\")\n",
        "\n",
        "    try:\n",
        "        feedback_response = ls_client.create_feedback(\n",
        "            test_run_id,\n",
        "            key=\"test-score\",\n",
        "            score=1.0,\n",
        "        )\n",
        "        print(\"‚úÖ Feedback creation successful!\")\n",
        "        print(f\"Feedback response: {feedback_response}\")\n",
        "\n",
        "    except Exception as feedback_error:\n",
        "        print(f\"‚ùå Feedback creation failed: {feedback_error}\")\n",
        "\n",
        "        # Let's try to get more details about the error\n",
        "        if hasattr(feedback_error, 'response'):\n",
        "            print(f\"Response status: {feedback_error.response.status_code}\")\n",
        "            print(f\"Response text: {feedback_error.response.text}\")\n",
        "\n",
        "        # Check if the run actually exists\n",
        "        print(f\"\\nüîç Checking if run exists...\")\n",
        "        try:\n",
        "            run_info = ls_client.read_run(test_run_id)\n",
        "            print(f\"‚úÖ Run exists: {run_info.id}\")\n",
        "        except Exception as read_error:\n",
        "            print(f\"‚ùå Run doesn't exist or can't be read: {read_error}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Trace creation failed: {e}\")\n",
        "\n",
        "# Test 4: Check project settings\n",
        "print(f\"\\nüß™ Test 4: Project Settings\")\n",
        "try:\n",
        "    project_name = os.environ.get(\"LANGSMITH_PROJECT\", \"default\")\n",
        "    print(f\"Current project: {project_name}\")\n",
        "\n",
        "    # Try to list projects\n",
        "    try:\n",
        "        # Note: This might not be available in all client versions\n",
        "        print(\"Attempting to check project access...\")\n",
        "    except Exception as e:\n",
        "        print(f\"Can't check projects: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Project check failed: {e}\")\n",
        "\n",
        "# Test 5: Alternative feedback approach\n",
        "print(f\"\\nüß™ Test 5: Alternative Feedback Approach\")\n",
        "print(\"Let's try the REST API directly for feedback...\")\n",
        "\n",
        "try:\n",
        "    # Create another simple trace first\n",
        "    alt_run_id = str(uuid.uuid4())\n",
        "\n",
        "    @traceable\n",
        "    def alt_test():\n",
        "        return \"alternative test\"\n",
        "\n",
        "    alt_result = alt_test(langsmith_extra={\"run_id\": alt_run_id})\n",
        "    time.sleep(1)  # Wait for processing\n",
        "\n",
        "    # Try direct API call for feedback\n",
        "    feedback_url = f\"https://api.smith.langchain.com/feedback\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {langsmith_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    feedback_data = {\n",
        "        \"run_id\": alt_run_id,\n",
        "        \"key\": \"direct-test\",\n",
        "        \"score\": 0.8\n",
        "    }\n",
        "\n",
        "    response = requests.post(feedback_url, headers=headers, json=feedback_data)\n",
        "    print(f\"Direct API feedback response: {response.status_code}\")\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ Direct API feedback worked!\")\n",
        "    else:\n",
        "        print(f\"‚ùå Direct API feedback failed: {response.text}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Direct API approach failed: {e}\")\n",
        "\n",
        "print(f\"\\nüìä Debug Summary Complete\")\n",
        "print(\"Check the results above to identify the specific issue.\")"
      ],
      "metadata": {
        "id": "aAiCFcenCn_c",
        "outputId": "9d634772-d3cf-4a31-8b1d-5c5527da8369",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Deep LangSmith Debugging...\n",
            "‚úÖ Using Personal Access Token: lsv2_pt_ae537ac...\n",
            "\n",
            "üß™ Test 1: Direct API Health Check\n",
            "API Status: 200\n",
            "‚úÖ LangSmith API is accessible\n",
            "\n",
            "üß™ Test 2: Client Initialization\n",
            "‚úÖ LangSmith Client created successfully\n",
            "‚ùå Can't list runs: Failed to POST /runs/query in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/query', '{\"detail\":\"At least one of \\'session\\', \\'id\\', \\'parent_run\\', \\'trace\\' or \\'reference_example\\' must be specified\"}')\n",
            "\n",
            "üß™ Test 3: Minimal Trace + Feedback Test\n",
            "Creating trace with run_id: 4fa97c93-b202-4e32-95e2-81b66ea35c78\n",
            "‚úÖ Trace created: Processed: test input\n",
            "üß™ Attempting to add feedback to run_id: 4fa97c93-b202-4e32-95e2-81b66ea35c78\n",
            "‚úÖ Feedback creation successful!\n",
            "Feedback response: id=UUID('00202f48-e7ef-4791-8978-5ec692e50645') created_at=datetime.datetime(2025, 9, 17, 18, 58, 23, 923456, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 9, 17, 18, 58, 23, 923461, tzinfo=datetime.timezone.utc) run_id=UUID('4fa97c93-b202-4e32-95e2-81b66ea35c78') trace_id=None key='test-score' score=1.0 value=None comment=None correction=None feedback_source=FeedbackSourceBase(type='api', metadata={}, user_id=None, user_name=None) session_id=None comparative_experiment_id=None feedback_group_id=None extra=None\n",
            "\n",
            "üß™ Test 4: Project Settings\n",
            "Current project: default\n",
            "Attempting to check project access...\n",
            "\n",
            "üß™ Test 5: Alternative Feedback Approach\n",
            "Let's try the REST API directly for feedback...\n",
            "Direct API feedback response: 401\n",
            "‚ùå Direct API feedback failed: {\"detail\":\"Invalid token\"}\n",
            "\n",
            "üìä Debug Summary Complete\n",
            "Check the results above to identify the specific issue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2 - Run the LangSmith enhanced version**\n",
        "\n",
        "The first thing you might want to trace is all your OpenAI calls. After all, this is where the LLM is actually being called, so it is the most important part! We've tried to make this as easy as possible with LangSmith by introducing a dead-simple OpenAI wrapper. All you have to do is modify your code to look something like:"
      ],
      "metadata": {
        "id": "jktFnZ1Eufxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we import from langsmith.wrappers import wrap_openai and use it to wrap the OpenAI client (openai_client = wrap_openai(OpenAI())).\n"
      ],
      "metadata": {
        "id": "OOBoFyHjuvZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we import from langsmith import traceable and use it decorate the overall function (@traceable).\n"
      ],
      "metadata": {
        "id": "bC55N2FvxTwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we import from langsmith import traceable and use it decorate the overall function (@traceable(run_type=\"retriever\")).\n",
        "\n",
        "What happens if you call it in the following way?"
      ],
      "metadata": {
        "id": "IaglAo68xmRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beta Testing\n",
        "The next stage of LLM application development is beta testing your application. This is when you release it to a few initial users. Having good observability set up here is crucial as often you don't know exactly how users will actually use your application, so this allows you get insights into how they do so. This also means that you probably want to make some changes to your tracing set up to better allow for that. This extends the observability you set up in the previous section\n",
        "\n",
        "# Collecting Feedback\n",
        "A huge part of having good observability during beta testing is collecting feedback. What feedback you collect is often application specific - but at the very least a simple thumbs up/down is a good start. After logging that feedback, you need to be able to easily associate it with the run that caused that. Luckily LangSmith makes it easy to do that.\n",
        "\n",
        "First, you need to log the feedback from your app. An easy way to do this is to keep track of a run ID for each run, and then use that to log feedback. Keeping track of the run ID would look something like:"
      ],
      "metadata": {
        "id": "AEzsGaWFxxzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging Metadata\n",
        "It is also a good idea to start logging metadata. This allows you to start keep track of different attributes of your app. This is important in allowing you to know what version or variant of your app was used to produce a given result.\n",
        "\n",
        "For this example, we will log the LLM used. Oftentimes you may be experimenting with different LLMs, so having that information as metadata can be useful for filtering. In order to do that, we can add it as such:"
      ],
      "metadata": {
        "id": "KZ6UsJ_eyMvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Working LangSmith RAG Application\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "from langsmith import traceable, Client\n",
        "import uuid\n",
        "\n",
        "# Load API keys from Colab Secrets\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n",
        "\n",
        "print(\"üîë Loaded API keys from Colab Secrets\")\n",
        "\n",
        "# Initialize clients\n",
        "openai_client = wrap_openai(OpenAI())\n",
        "ls_client = Client()\n",
        "\n",
        "@traceable(run_type=\"retriever\")\n",
        "def retriever(query: str):\n",
        "    results = [\"Harrison worked at Kensho\"]\n",
        "    return results\n",
        "\n",
        "@traceable(metadata={\"llm\": \"gpt-4o-mini\"})\n",
        "def rag(question):\n",
        "    docs = retriever(question)\n",
        "    system_message = \"\"\"Answer the users question using only the provided information below:\n",
        "\n",
        "    {docs}\"\"\".format(docs=\"\\n\".join(docs))\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "print(\"üöÄ Starting RAG application tests...\")\n",
        "\n",
        "# Test 1: Successful run\n",
        "print(\"\\n‚úÖ Test 1: Successful run\")\n",
        "run_id = str(uuid.uuid4())\n",
        "print(f\"Run ID: {run_id}\")\n",
        "\n",
        "result = rag(\n",
        "    \"where did harrison work\",\n",
        "    langsmith_extra={\"run_id\": run_id, \"metadata\": {\"user_id\": \"harrison\"}}\n",
        ")\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "# Add positive feedback\n",
        "feedback_response = ls_client.create_feedback(\n",
        "    run_id,\n",
        "    key=\"user-score\",\n",
        "    score=1.0,\n",
        ")\n",
        "print(f\"‚úÖ Positive feedback added successfully\")\n",
        "\n",
        "# Test 2: \"Failed\" run (will still work but gets negative feedback)\n",
        "print(\"\\n‚ùå Test 2: Failed run (negative feedback)\")\n",
        "run_id = str(uuid.uuid4())\n",
        "print(f\"Run ID: {run_id}\")\n",
        "\n",
        "result = rag(\n",
        "    \"where did peter work\",\n",
        "    langsmith_extra={\"run_id\": run_id, \"metadata\": {\"user_id\": \"peter\"}}\n",
        ")\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "# Add negative feedback\n",
        "feedback_response = ls_client.create_feedback(\n",
        "    run_id,\n",
        "    key=\"user-score\",\n",
        "    score=0.0,\n",
        ")\n",
        "print(f\"‚úÖ Negative feedback added successfully\")\n",
        "\n",
        "print(f\"\\nüéâ Both tests completed successfully!\")\n",
        "print(f\"üìä Now you can proceed with the homework assignment:\")\n",
        "print(f\"1. Go to https://smith.langchain.com/projects\")\n",
        "print(f\"2. Click on your recent runs\")\n",
        "print(f\"3. Explore the trace view, metadata, and feedback as described in the homework\")\n",
        "print(f\"4. Use the feedback tab to filter by positive/negative feedback\")\n",
        "print(f\"5. Check out the monitoring dashboard\")\n",
        "\n",
        "print(f\"\\nüîç Your traces should show:\")\n",
        "print(f\"- Full RAG ‚Üí Retriever ‚Üí OpenAI call structure\")\n",
        "print(f\"- Custom metadata (user_id, llm model)\")\n",
        "print(f\"- Feedback scores (1.0 for Harrison, 0.0 for Peter)\")"
      ],
      "metadata": {
        "id": "h_jOkBaMDMOT",
        "outputId": "2f7784d4-a0cd-4b36-801f-e522edef939a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Loaded API keys from Colab Secrets\n",
            "üöÄ Starting RAG application tests...\n",
            "\n",
            "‚úÖ Test 1: Successful run\n",
            "Run ID: e6592c67-9adc-4b24-990e-1a2789d01289\n",
            "Response: Harrison worked at Kensho.\n",
            "‚úÖ Positive feedback added successfully\n",
            "\n",
            "‚ùå Test 2: Failed run (negative feedback)\n",
            "Run ID: e9764a7e-32b1-4e5e-95c3-4aeca43ee4cd\n",
            "Response: The provided information does not mention where Peter worked.\n",
            "‚úÖ Negative feedback added successfully\n",
            "\n",
            "üéâ Both tests completed successfully!\n",
            "üìä Now you can proceed with the homework assignment:\n",
            "1. Go to https://smith.langchain.com/projects\n",
            "2. Click on your recent runs\n",
            "3. Explore the trace view, metadata, and feedback as described in the homework\n",
            "4. Use the feedback tab to filter by positive/negative feedback\n",
            "5. Check out the monitoring dashboard\n",
            "\n",
            "üîç Your traces should show:\n",
            "- Full RAG ‚Üí Retriever ‚Üí OpenAI call structure\n",
            "- Custom metadata (user_id, llm model)\n",
            "- Feedback scores (1.0 for Harrison, 0.0 for Peter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observing what happens\n",
        "\n",
        "You have now just run a app with Langsmith integreated with 1)tracing, 2)extra metadata, 3)feedback.\n",
        "\n",
        "After successfully running this, let's goto the LangSmith website to check out\n",
        "1)the traces from Rag to retriever to the OpenAI call\n",
        "2)the metadata that we added on user_id and llm model\n",
        "3)the feedback added for the track.\n",
        "\n",
        "\n",
        "Next, let's try to query by feedback that is positive\n",
        "\n",
        "Next, let's try to query the feedback that is negative.\n",
        "\n",
        "Last, let's look at the monitoring dashboard."
      ],
      "metadata": {
        "id": "VxXmTNaPHTTU"
      }
    }
  ]
}